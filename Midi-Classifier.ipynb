{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pretty_midi\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Genre             TrackID\n",
      "0  Pop_Rock  TRAAAAK128F9318786\n",
      "1       Rap  TRAAAAW128F429D538\n",
      "2  Pop_Rock  TRAAABD128F429CF47\n",
      "3      Jazz  TRAAAED128E0783FAB\n",
      "4  Pop_Rock  TRAAAEF128F4273421\n",
      "\n",
      "['RnB', 'Pop_Rock', 'Blues', 'International', 'Reggae', 'Jazz', 'New Age', 'Folk', 'Latin', 'Vocal', 'Electronic', 'Country', 'Rap']\n",
      "\n",
      "{'RnB': 0, 'Pop_Rock': 1, 'Blues': 2, 'International': 3, 'Reggae': 4, 'Jazz': 5, 'New Age': 6, 'Folk': 7, 'Latin': 8, 'Vocal': 9, 'Electronic': 10, 'Country': 11, 'Rap': 12}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_genres(path):\n",
    "    \"\"\"\n",
    "    This function reads the genre labels and puts it into a pandas DataFrame.\n",
    "    \n",
    "    @input path: The path to the genre label file.\n",
    "    @type path: String\n",
    "    \n",
    "    @return: A pandas dataframe containing the genres and midi IDs.\n",
    "    @rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    genres = []\n",
    "    with open(path) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            if line[0] != '#':\n",
    "                [x, y, *_] = line.strip().split(\"\\t\")\n",
    "                ids.append(x)\n",
    "                genres.append(y)\n",
    "            line = f.readline()\n",
    "    genre_df = pd.DataFrame(data={\"Genre\": genres, \"TrackID\": ids})\n",
    "    return genre_df\n",
    "\n",
    "# Get the Genre DataFrame\n",
    "genre_path = \"msd_tagtraum_cd1.cls\"\n",
    "genre_df = get_genres(genre_path)\n",
    "\n",
    "# Create Genre List and Dictionary\n",
    "label_list = list(set(genre_df.Genre))\n",
    "label_dict = {lbl: label_list.index(lbl) for lbl in label_list}\n",
    "\n",
    "# Print to Visualize\n",
    "print(genre_df.head(), end=\"\\n\\n\")\n",
    "print(label_list, end=\"\\n\\n\")\n",
    "print(label_dict, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Path     Genre\n",
      "0  lmd_matched/R/R/U/TRRRUFD12903CD7092/6c460e4c5...  Pop_Rock\n",
      "1  lmd_matched/R/R/U/TRRRUFD12903CD7092/6ca2a1f03...  Pop_Rock\n",
      "2  lmd_matched/R/R/A/TRRRAJP128E0793859/2c78d25cb...       RnB\n",
      "3  lmd_matched/R/R/F/TRRRFLX128F9326186/afd3595e5...  Pop_Rock\n",
      "4  lmd_matched/R/R/F/TRRRFLX128F9326186/74582fd38...  Pop_Rock\n"
     ]
    }
   ],
   "source": [
    "def get_matched_midi(midi_folder, genre_df):\n",
    "    \"\"\"\n",
    "    This function loads in midi file paths that are found in the given folder, puts this data into a\n",
    "    pandas DataFrame, then matches each entry with a genre described in get_genres.\n",
    "    \n",
    "    @input midi_folder: The path to the midi files.\n",
    "    @type midi_folder: String\n",
    "    @input genre_df: The genre label dataframe generated by get_genres.\n",
    "    @type genre_df: pandas.DataFrame\n",
    "    \n",
    "    @return: A dataframe of track id and path to a midi file with that track id.\n",
    "    @rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    # Get All Midi Files\n",
    "    track_ids, file_paths = [], []\n",
    "    for dir_name, subdir_list, file_list in os.walk(midi_folder):\n",
    "        if len(dir_name) == 36:\n",
    "            track_id = dir_name[18:]\n",
    "            file_path_list = [\"/\".join([dir_name, file]) for file in file_list]\n",
    "            for file_path in file_path_list:\n",
    "                track_ids.append(track_id)\n",
    "                file_paths.append(file_path)\n",
    "    all_midi_df = pd.DataFrame({\"TrackID\": track_ids, \"Path\": file_paths})\n",
    "    \n",
    "    # Inner Join with Genre Dataframe\n",
    "    df = pd.merge(all_midi_df, genre_df, on='TrackID', how='inner')\n",
    "    return df.drop([\"TrackID\"], axis=1)\n",
    "\n",
    "# Obtain DataFrame with Matched Genres to File Paths\n",
    "midi_path = \"lmd_matched\"\n",
    "matched_midi_df = get_matched_midi(midi_path, genre_df)\n",
    "\n",
    "# Print to Check Correctness\n",
    "print(matched_midi_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15523849  0.55        0.125       0.125       1.        ]\n",
      " [ 0.15523849  0.55        0.125       0.125       1.        ]\n",
      " [ 0.06335386 -0.17        0.125       0.125       0.        ]\n",
      " ...\n",
      " [ 0.43089736  0.55        0.125       0.125       1.        ]\n",
      " [ 0.4333338  -0.35        0.125       0.125       1.        ]\n",
      " [ 0.41467545  1.91        0.125       0.125       1.        ]]\n",
      "CPU times: user 52min 7s, sys: 1min 21s, total: 53min 29s\n",
      "Wall time: 56min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def normalize_features(features):\n",
    "    \"\"\"\n",
    "    This function normalizes the features to the range [-1, 1]\n",
    "    \n",
    "    @input features: The array of features.\n",
    "    @type features: List of float\n",
    "    \n",
    "    @return: Normalized features.\n",
    "    @rtype: List of float\n",
    "    \"\"\"\n",
    "    tempo = (features[0] - 150) / 300\n",
    "    num_sig_changes = (features[1] - 2) / 10\n",
    "    resolution = (features[2] - 260) / 400\n",
    "    time_sig_1 = (features[3] - 3) / 8\n",
    "    time_sig_2 = (features[4] - 3) / 8\n",
    "    return [tempo, resolution, time_sig_1, time_sig_2]\n",
    "\n",
    "\n",
    "def get_features(path):\n",
    "    \"\"\"\n",
    "    This function extracts the features from a midi file when given its path.\n",
    "    \n",
    "    @input path: The path to the midi file.\n",
    "    @type path: String\n",
    "    \n",
    "    @return: The extracted features.\n",
    "    @rtype: List of float\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Test for Corrupted Midi Files\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"error\")\n",
    "            file = pretty_midi.PrettyMIDI(path)\n",
    "            \n",
    "            tempo = file.estimate_tempo()\n",
    "            num_sig_changes = len(file.time_signature_changes)\n",
    "            resolution = file.resolution\n",
    "            ts_changes = file.time_signature_changes\n",
    "            ts_1 = 4\n",
    "            ts_2 = 4\n",
    "            if len(ts_changes) > 0:\n",
    "                ts_1 = ts_changes[0].numerator\n",
    "                ts_2 = ts_changes[0].denominator\n",
    "            return normalize_features([tempo, num_sig_changes, resolution, ts_1, ts_2])\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_midi_features(path_df):\n",
    "    \"\"\"\n",
    "    This function takes in the path DataFrame, then for each midi file, it extracts certain\n",
    "    features, maps the genre to a number and concatenates these to a large design matrix to return.\n",
    "    \n",
    "    @input path_df: A dataframe with paths to midi files, as well as their corresponding matched genre.\n",
    "    @type path_df: pandas.DataFrame\n",
    "    \n",
    "    @return: A matrix of features along with label.\n",
    "    @rtype: numpy.ndarray of float\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    for index, row in path_df.iterrows():\n",
    "        features = get_features(row.Path)\n",
    "        genre = label_dict[row.Genre]\n",
    "        if features is not None:\n",
    "            features.append(genre)\n",
    "            all_features.append(features)\n",
    "    return np.array(all_features)\n",
    "\n",
    "labeled_features = extract_midi_features(matched_midi_df)\n",
    "print(labeled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16666667  0.55        0.125       0.125     ]\n",
      " [ 0.24169193  0.31        0.125       0.125     ]\n",
      " [ 0.2140467  -0.35        0.125       0.125     ]\n",
      " [ 0.1556701  -0.35        1.125       0.625     ]\n",
      " [ 0.30061672 -0.35        0.125       0.125     ]\n",
      " [-0.02216318 -0.4325      0.125       0.125     ]\n",
      " [ 0.12371831 -0.35        0.125       0.125     ]\n",
      " [ 0.14516129 -0.35        0.125       0.125     ]\n",
      " [ 0.02754932  0.55        0.125       0.125     ]\n",
      " [ 0.34615646 -0.17        0.125       0.125     ]]\n",
      "[ 1 11  8  1 11  1  1 10  1 11]\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle Entire Dataset to Make Random\n",
    "labeled_features = np.random.permutation(labeled_features)\n",
    "\n",
    "# Partition into 3 Sets\n",
    "num = len(labeled_features)\n",
    "num_training = int(num * 0.6)\n",
    "num_validation = int(num * 0.8)\n",
    "training_data = labeled_features[:num_training]\n",
    "validation_data = labeled_features[num_training:num_validation]\n",
    "test_data = labeled_features[num_validation:]\n",
    "\n",
    "# Separate Features from Labels\n",
    "num_cols = training_data.shape[1] - 1\n",
    "training_features = training_data[:, :num_cols]\n",
    "validation_features = validation_data[:, :num_cols]\n",
    "test_features = test_data[:, :num_cols]\n",
    "\n",
    "# Format Features for Multi-class Classification\n",
    "num_classes = len(label_list)\n",
    "training_labels = training_data[:, num_cols].astype(int)\n",
    "validation_labels = validation_data[:, num_cols].astype(int)\n",
    "test_labels = test_data[:, num_cols].astype(int)\n",
    "\n",
    "# Function for One-Hot Encoding\n",
    "def one_hot(labels):\n",
    "    \"\"\"\n",
    "    This function encodes the labels using one-hot encoding.\n",
    "    \n",
    "    @input num_classes: The number of genres/classes.\n",
    "    @type num_classes: int\n",
    "    @input labels: The genre labels to encode.\n",
    "    @type labels: numpy.ndarray of int\n",
    "    \n",
    "    @return: The one-hot encoding of the labels.\n",
    "    @rtype: numpy.ndarray of int\n",
    "    \"\"\"\n",
    "    return np.eye(num_classes)[labels].astype(int)\n",
    "\n",
    "# Print to Check Dimentions and to Visualize\n",
    "print(test_features[:10])\n",
    "print(test_labels[:10])\n",
    "print(one_hot(test_labels)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.7392172523961661\n"
     ]
    }
   ],
   "source": [
    "def train_model(t_features, t_labels, v_features, v_labels):\n",
    "    \"\"\"\n",
    "    This function trains a neural network using a couple different configurations.\n",
    "    \n",
    "    @input t_features: The training features.\n",
    "    @type t_features: numpy.ndarray of float\n",
    "    @input t_labels: The training labels.\n",
    "    @type t_labels: numpy.ndarray of int\n",
    "    @input v_features: The validation features.\n",
    "    @type v_features: numpy.ndarray of float\n",
    "    @input v_labels: The validation labels.\n",
    "    @type v_labels: numpy.ndarray of int\n",
    "    \n",
    "    @return: The classifier that achieved the best validation accuracy.\n",
    "    @rtype: sklearn.neural_network.multilayer_perceptron.MLPClassifier\n",
    "    \"\"\"\n",
    "    # Neural Network and SVM Configurations\n",
    "    clf_1 = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(5,), random_state=1)\n",
    "    clf_2 = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(5, 5), random_state=1)\n",
    "    clf_3 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(10, 10), random_state=1)\n",
    "    clf_4 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 100), random_state=1)\n",
    "    clf_svm = SVC()\n",
    "    \n",
    "    # Keep Track of the Best Model\n",
    "    best_clf = None\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    # Test the Accuracies of the Models and Get Best\n",
    "    for clf in [clf_1, clf_2, clf_3, clf_4, clf_svm]:\n",
    "        t_labels_hot = one_hot(t_labels)\n",
    "        v_labels_hot = one_hot(v_labels)\n",
    "        if (type(clf) == SVC):\n",
    "            clf = clf.fit(t_features, t_labels)\n",
    "        else:\n",
    "            clf = clf.fit(t_features, t_labels_hot)\n",
    "        predictions = clf.predict(v_features)\n",
    "        count = 0\n",
    "        for i in range(len(v_labels)):\n",
    "            if (type(clf) != SVC):\n",
    "                if np.array_equal(v_labels_hot[i], predictions[i]):\n",
    "                    count += 1\n",
    "            else:\n",
    "                if v_labels[i] == predictions[i]:\n",
    "                    count += 1\n",
    "        accuracy = count / len(v_labels_hot)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_clf = clf\n",
    "\n",
    "    print(\"Best Accuracy:\", best_accuracy)\n",
    "    return best_clf\n",
    "\n",
    "classifier = train_model(training_features, training_labels, validation_features, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7321357285429142\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(clf, t_features, t_labels):\n",
    "    \"\"\"\n",
    "    This function takes a trained model as well as the test features and its\n",
    "    corresponding labels, and reports the accuracy of the model.\n",
    "    \n",
    "    @input clf: The trained classifier.\n",
    "    @type model: sklearn.neural_network.multilayer_perceptron.MLPClassifier\n",
    "    @input t_features: The features from the test set.\n",
    "    @type f_features: numpy.ndarray of float\n",
    "    @input t_labels: The labels of the test set features.\n",
    "    @type t_labels: numpy.ndarray of int\n",
    "    \n",
    "    @return: The accuracy.\n",
    "    @rtype: float\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    predictions = clf.predict(t_features)\n",
    "    t_labels_hot = one_hot(t_labels)\n",
    "    for i in range(len(t_features)):\n",
    "        if (type(clf) == SVC):\n",
    "            if t_labels[i] == predictions[i]:\n",
    "                count += 1\n",
    "        else:\n",
    "            if np.array_equal(t_labels_hot[i], predictions[i]):\n",
    "                count += 1\n",
    "    return count / len(t_features)\n",
    "\n",
    "# Print the Test Accuracy\n",
    "print(calculate_accuracy(classifier, test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop_Rock\n"
     ]
    }
   ],
   "source": [
    "def make_prediction(clf, midi_path):\n",
    "    \"\"\"\n",
    "    This function uses the classifier to predict the genre of a midi file.\n",
    "    \n",
    "    @input clf: The trained classifier.\n",
    "    @type clf: sklearn.neural_network.multilayer_perceptron.MLPClassifier\n",
    "    @input midi_path: The path to the midi file that we are trying to classify.\n",
    "    @type midi_path: String\n",
    "    \n",
    "    @return: The predicted genre of the midi file.\n",
    "    @rtype: String\n",
    "    \"\"\"\n",
    "    features = get_features(midi_path)\n",
    "    prediction_ind = list(clf.predict([features])[0]).index(1)\n",
    "    prediction = label_list[prediction_ind]\n",
    "    return prediction\n",
    "    \n",
    "# Make a Prediction\n",
    "test_midi_path =\"lmd_matched/B/F/E/TRBFELB128F426BFF2/289270d85c81802d912c9907c645dc2d.mid\"\n",
    "print(make_prediction(classifier, test_midi_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pop_Rock\n"
     ]
    }
   ],
   "source": [
    "output = \"./output_midi/base_model_30_bars/from_scratch/16.midi\"\n",
    "print(make_prediction(classifier, output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
